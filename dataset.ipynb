{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxH+t94kPUfCMM5e3I9vjb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charchar1245/Transformer-for-Translating-English-to-Spanish/blob/main/dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download es_core_news_sm"
      ],
      "metadata": {
        "id": "G2Mtx2RCt6jW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95db52c4-c49f-4fec-9321-2a79723251dd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting es-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKjYwofds4ww",
        "outputId": "ab31cadc-3372-4b41-adad-1b9c3479b3b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Import dataset from Huggingface\n",
        "ds = load_dataset(\"okezieowen/english_to_spanish\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For testing purposes in this file, we will just take the first 10 sentences from the data\n",
        "selected_data = ds['train'].select(range(10))\n",
        "df = selected_data.to_pandas()"
      ],
      "metadata": {
        "id": "5JUt1ZuHs_ri"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "# Tokenize text\n",
        "def tokenize(text, language):\n",
        "  if language == 'en':\n",
        "    spacy_en = spacy.load(\"en_core_web_sm\")\n",
        "    return [token.text for token in spacy_en.tokenizer(text)]\n",
        "  elif language == 'es':\n",
        "    spacy_es = spacy.load(\"es_core_news_sm\")\n",
        "  return [token.text for token in spacy_es.tokenizer(text)]\n",
        "\n",
        "\n",
        "# New variable for tokenized text\n",
        "all_tokens_english = [tokenize(sentence, 'en') for sentence in df['English'] if sentence is not None]\n",
        "\n",
        "all_tokens_spanish = [tokenize(sentence, 'es') for sentence in df['Spanish'] if sentence is not None]\n"
      ],
      "metadata": {
        "id": "hsZjtzdzujON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf64b0eb-90b4-41e6-fe47-0d5fc6d562d9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/platform/asyncio.py\", line 211, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
            "    await result\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-2275130447.py\", line 1, in <cell line: 0>\n",
            "    import spacy\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/spacy/__init__.py\", line 6, in <module>\n",
            "    from .errors import setup_default_warnings\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/spacy/errors.py\", line 3, in <module>\n",
            "    from .compat import Literal\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/spacy/compat.py\", line 5, in <module>\n",
            "    from thinc.util import copy_array\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/thinc/__init__.py\", line 5, in <module>\n",
            "    from .config import registry\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/thinc/config.py\", line 5, in <module>\n",
            "    from .types import Decorator\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/thinc/types.py\", line 27, in <module>\n",
            "    from .compat import cupy, has_cupy\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/thinc/compat.py\", line 35, in <module>\n",
            "    import torch\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for tokens in all_tokens_spanish:\n",
        "  print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6FHs_Ny63yB",
        "outputId": "2838646d-5488-4104-da4c-1819425ce5dc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Declaro', 'reanudado', 'el', 'período', 'de', 'sesiones', 'del', 'Parlamento', 'Europeo', ',', 'interrumpido', 'el', 'viernes', '17', 'de', 'diciembre', 'pasado', ',', 'y', 'reitero', 'a', 'Sus', 'Señorías', 'mi', 'deseo', 'de', 'que', 'hayan', 'tenido', 'unas', 'buenas', 'vacaciones', '.']\n",
            "['Como', 'todos', 'han', 'podido', 'comprobar', ',', 'el', 'gran', '\"', 'efecto', 'del', 'año', '2000', '\"', 'no', 'se', 'ha', 'producido', '.', 'En', 'cambio', ',', 'los', 'ciudadanos', 'de', 'varios', 'de', 'nuestros', 'países', 'han', 'sido', 'víctimas', 'de', 'catástrofes', 'naturales', 'verdaderamente', 'terribles', '.']\n",
            "['Sus', 'Señorías', 'han', 'solicitado', 'un', 'debate', 'sobre', 'el', 'tema', 'para', 'los', 'próximos', 'días', ',', 'en', 'el', 'curso', 'de', 'este', 'período', 'de', 'sesiones', '.']\n",
            "['A', 'la', 'espera', 'de', 'que', 'se', 'produzca', ',', 'de', 'acuerdo', 'con', 'muchos', 'colegas', 'que', 'me', 'lo', 'han', 'pedido', ',', 'pido', 'que', 'hagamos', 'un', 'minuto', 'de', 'silencio', 'en', 'memoria', 'de', 'todas', 'las', 'víctimas', 'de', 'las', 'tormentas', ',', 'en', 'los', 'distintos', 'países', 'de', 'la', 'Unión', 'Europea', 'afectados', '.']\n",
            "['Invito', 'a', 'todos', 'a', 'que', 'nos', 'pongamos', 'de', 'pie', 'para', 'guardar', 'un', 'minuto', 'de', 'silencio', '.']\n",
            "['(', 'El', 'Parlamento', ',', 'de', 'pie', ',', 'guarda', 'un', 'minuto', 'de', 'silencio', ')']\n",
            "['Señora', 'Presidenta', ',', 'una', 'cuestión', 'de', 'procedimiento', '.']\n",
            "['Sabrá', 'usted', 'por', 'la', 'prensa', 'y', 'la', 'televisión', 'que', 'se', 'han', 'producido', 'una', 'serie', 'de', 'explosiones', 'y', 'asesinatos', 'en', 'Sri', 'Lanka', '.']\n",
            "['Una', 'de', 'las', 'personas', 'que', 'recientemente', 'han', 'asesinado', 'en', 'Sri', 'Lanka', 'ha', 'sido', 'al', 'Sr.', 'Kumar', 'Ponnambalam', ',', 'quien', 'hace', 'pocos', 'meses', 'visitó', 'el', 'Parlamento', 'Europeo', '.']\n",
            "['¿', 'Sería', 'apropiado', 'que', 'usted', ',', 'Señora', 'Presidenta', ',', 'escribiese', 'una', 'carta', 'al', 'Presidente', 'de', 'Sri', 'Lanka', 'expresando', 'las', 'condolencias', 'del', 'Parlamento', 'por', 'esa', 'y', 'otras', 'muertes', 'violentas', ',', 'pidiéndole', 'que', 'haga', 'todo', 'lo', 'posible', 'para', 'encontrar', 'una', 'reconciliación', 'pacífica', 'ante', 'la', 'extremadamente', 'difícil', 'situación', 'que', 'está', 'viviendo', 'su', 'país', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch torchtext\n",
        "!pip install torch==2.2.2 torchtext==0.17.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Xu1AwyK87FFR",
        "outputId": "a60e0191-dea2-4cef-d402-fb80e43e79bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.9.0+cpu\n",
            "Uninstalling torch-2.9.0+cpu:\n",
            "  Successfully uninstalled torch-2.9.0+cpu\n",
            "\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch==2.2.2\n",
            "  Downloading torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting torchtext==0.17.2\n",
            "  Downloading torchtext-0.17.2-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext==0.17.2) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext==0.17.2) (2.32.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchtext==0.17.2) (2.0.2)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.2.2) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.17.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.17.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.17.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.17.2) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.2.2) (1.3.0)\n",
            "Downloading torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.17.2-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m839.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchtext\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.28.9\n",
            "    Uninstalling nvidia-nccl-cu12-2.28.9:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.28.9\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.9.0+cpu requires torch==2.9.0, but you have torch 2.2.2 which is incompatible.\n",
            "torchvision 0.24.0+cpu requires torch==2.9.0, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 torchtext-0.17.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "b1e60b246b09482f89e107d5a6960374"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "vocab_english = build_vocab_from_iterator(\n",
        "    all_tokens_english,\n",
        "    min_freq=1,\n",
        "    specials=[\"<unk>\", \"<pad>\"],\n",
        "    special_first=True\n",
        ")\n",
        "\n",
        "vocab_spanish = build_vocab_from_iterator(\n",
        "    all_tokens_spanish,\n",
        "    min_freq=1,\n",
        "    specials=[\"<unk>\", \"<pad>\"],\n",
        "    special_first=True\n",
        ")\n",
        "\n",
        "print(vocab_english.get_itos())\n",
        "print(vocab_spanish.get_itos())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Afnj2BlAtcy",
        "outputId": "005bd63c-a327-4f3a-ee55-8069145228d3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>', '<pad>', 'the', ',', 'a', 'of', '.', 'to', 'in', 'and', \"'\", 'Sri', 'have', 'on', 'you', 'European', 'I', 'Lanka', 'Parliament', 'President', 'minute', 'number', 's', 'silence', 'that', 'this', 'Madam', 'You', 'as', 'be', 'countries', 'few', 'for', 'like', 'people', 'requested', 'session', 'very', 'will', \"'s\", '(', ')', '-', '17', '1999', '?', 'Although', 'December', 'Friday', 'House', 'In', 'Kumar', 'Lankan', 'Members', 'Mr', 'One', 'Please', 'Ponnambalam', 'The', 'Union', 'Would', 'adjourned', 'again', 'ago', 'all', 'appropriate', 'assassinated', 'at', 'aware', 'been', 'behalf', 'bomb', 'bug', 'can', 'concerned', 'course', 'days', 'deaths', 'debate', 'declare', 'difficult', 'disasters', 'do', 'dreaded', 'dreadful', 'during', 'enjoyed', 'everything', 'explosions', 'expressing', 'failed', 'festive', 'from', 'had', 'happy', 'her', 'his', 'hope', 'it', 'just', 'killings', 'letter', 'materialise', 'meantime', 'millennium', 'months', 'natural', 'new', 'next', 'observe', 'observed', 'once', 'order', 'other', 'part', 'particularly', 'peaceful', 'period', 'pleasant', 'point', 'possibly', 'press', 'recently', 'reconciliation', 'regret', 'resumed', 'rise', 'rose', 'seek', 'seen', 'series', 'she', 'should', 'situation', 'still', 'storms', 'subject', 'suffered', 'television', 'terrible', 'then', 'there', 'those', 'truly', 'urging', 'various', 'victims', 'violent', 'visited', 'was', 'were', 'who', 'wish', 'would', 'write', 'year']\n",
            "['<unk>', '<pad>', 'de', ',', 'que', '.', 'el', 'han', 'en', 'la', 'Parlamento', 'las', 'un', 'una', 'y', 'Lanka', 'Sri', 'a', 'del', 'los', 'minuto', 'para', 'se', 'silencio', '\"', 'Europeo', 'Presidenta', 'Señora', 'Señorías', 'Sus', 'al', 'ha', 'lo', 'países', 'período', 'pie', 'por', 'producido', 'sesiones', 'sido', 'todos', 'usted', 'víctimas', '(', ')', '17', '2000', '?', 'A', 'Como', 'Declaro', 'El', 'En', 'Europea', 'Invito', 'Kumar', 'Ponnambalam', 'Presidente', 'Sabrá', 'Sería', 'Sr.', 'Una', 'Unión', 'acuerdo', 'afectados', 'ante', 'apropiado', 'asesinado', 'asesinatos', 'año', 'buenas', 'cambio', 'carta', 'catástrofes', 'ciudadanos', 'colegas', 'comprobar', 'con', 'condolencias', 'cuestión', 'curso', 'debate', 'deseo', 'diciembre', 'difícil', 'distintos', 'días', 'efecto', 'encontrar', 'esa', 'escribiese', 'espera', 'este', 'está', 'explosiones', 'expresando', 'extremadamente', 'gran', 'guarda', 'guardar', 'hace', 'haga', 'hagamos', 'hayan', 'interrumpido', 'me', 'memoria', 'meses', 'mi', 'muchos', 'muertes', 'naturales', 'no', 'nos', 'nuestros', 'otras', 'pacífica', 'pasado', 'país', 'pedido', 'personas', 'pidiéndole', 'pido', 'pocos', 'podido', 'pongamos', 'posible', 'prensa', 'procedimiento', 'produzca', 'próximos', 'quien', 'reanudado', 'recientemente', 'reconciliación', 'reitero', 'serie', 'situación', 'sobre', 'solicitado', 'su', 'televisión', 'tema', 'tenido', 'terribles', 'todas', 'todo', 'tormentas', 'unas', 'vacaciones', 'varios', 'verdaderamente', 'viernes', 'violentas', 'visitó', 'viviendo', '¿']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Numericalize the all_tokens array\n",
        "def numericalize_and_pad(vocab, list_of_token_lists, sentence_size):\n",
        "  numericalized_unpadded = [vocab(tokens) for tokens in list_of_token_lists]\n",
        "  # For each sentence, subtract max size from size of that token and create array of size difference full of padding index\n",
        "  # Pad index is concatenated to numericalized sentence\n",
        "  # Return tensor full of numericalized and padded sentences\n",
        "  numericalized_sentences = []\n",
        "  for sentence in numericalized_unpadded:\n",
        "    if len(sentence) > sentence_size:\n",
        "      sentence = sentence[:sentence_size]\n",
        "      numericalized_sentences.append(sentence)\n",
        "    else:\n",
        "      padding_size = sentence_size - len(sentence)\n",
        "      padding = [vocab[\"<pad>\"] for _ in range(padding_size)]\n",
        "      sentence.extend(padding)\n",
        "      numericalized_sentences.append(sentence)\n",
        "\n",
        "\n",
        "  return torch.tensor(numericalized_sentences)\n",
        "\n",
        "print(numericalize_and_pad(vocab_english, all_tokens_english, 100)[0])\n",
        "print(numericalize_and_pad(vocab_english, all_tokens_english, 100).shape)\n",
        "\n",
        "print(numericalize_and_pad(vocab_spanish, all_tokens_spanish, 100)[0])\n",
        "print(numericalize_and_pad(vocab_spanish, all_tokens_spanish, 100).shape)\n",
        "\n",
        "english_sentence_ids = numericalize_and_pad(vocab_english, all_tokens_english, 100)\n",
        "spanish_sentence_ids = numericalize_and_pad(vocab_spanish, all_tokens_spanish, 100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMTCHcL1JI95",
        "outputId": "5a1e5e1b-b1c0-426a-f916-d735334dc547"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 16,  79, 125,   2,  36,   5,   2,  15,  18,  61,  13,  48,  43,  47,\n",
            "         44,   3,   9,  16, 153,  33, 111,  62,   7, 152,  14,   4,  94, 107,\n",
            "        155,   8,   2,  97,  24,  14,  86,   4, 118,  91, 117,   6,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1])\n",
            "torch.Size([10, 100])\n",
            "tensor([ 50, 132,   6,  34,   2,  38,  18,  10,  25,   3, 104,   6, 152,  45,\n",
            "          2,  83, 117,   3,  14, 135,  17,  29,  28, 108,  82,   2,   4, 103,\n",
            "        143, 148,  70, 149,   5,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1])\n",
            "torch.Size([10, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding function: Map an input vector to a d_model sized embedding represtation (each token is represtned by d_model numbers)\n",
        "# English and Spanish will have different embeddings\n",
        "\n",
        "vocab_size_english = len(vocab_english.get_itos())\n",
        "vocab_size_spanish = len(vocab_spanish.get_itos())\n",
        "d_model = 256\n",
        "\n",
        "def embedding(sentence_ids, d_model, vocab_size):\n",
        "  embedding_layer = torch.nn.Embedding(vocab_size, d_model)\n",
        "  return embedding_layer(sentence_ids)\n",
        "\n",
        "input_embeddings_english = embedding(english_sentence_ids, d_model, vocab_size_english)\n",
        "input_embeddings_spanish = embedding(spanish_sentence_ids, d_model, vocab_size_spanish)\n",
        "\n",
        "print(input_embeddings_english.shape)\n",
        "print(input_embeddings_spanish.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVWvR2TBoJAj",
        "outputId": "1988da86-adfe-44ff-9d05-92b8694c211b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 100, 256])\n",
            "torch.Size([10, 100, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "import math\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "vSDC82WurAIj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positional_encoding_english = PositionalEncoding(d_model)\n",
        "positional_encoding_spanish = PositionalEncoding(d_model)\n",
        "\n",
        "input_embeddings_english = positional_encoding_english(input_embeddings_english)\n",
        "input_embeddings_spanish = positional_encoding_spanish(input_embeddings_spanish)"
      ],
      "metadata": {
        "id": "3aqruhgKro8o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}